model_config:
  patch_size: 8
  num_patches: 64
  output_size: 128
  input_image_size: 64
  channels: 3
  emb_size: 256
  num_heads: 8
  depth: 6
  scale_factor: 2 # This represents the upscaling factor for spatial dimensions
  block_size: 8 # Example block size for attention mechanisms
  dim: 256 # Dimension for transformer embeddings, matching SFEB output
  num_features: 2
  stages: 2
  block_per_stage: 2
  final_image_size: 128
  patch_target_size: 16 # after reconstruction each patch is (patch size * scale factor)
  hidden_features: 128
